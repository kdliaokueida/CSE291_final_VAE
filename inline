{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "mean = [0, 0]\n",
    "cov = [[1, 0], [0, 100]]\n",
    "\n",
    "X = np.random.multivariate_normal(mean, cov, 60000)\n",
    "\n",
    "\n",
    "mb_size = 32\n",
    "Z_dim = 5\n",
    "X_dim = X.shape[1]\n",
    "h_dim = 128\n",
    "c = 0\n",
    "lr = 1e-3\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== Q(z|X) ======================================\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whz_mu = xavier_init(size=[h_dim, Z_dim])\n",
    "bhz_mu = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "Whz_var = xavier_init(size=[h_dim, Z_dim])\n",
    "bhz_var = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def Q(X):\n",
    "    h = nn.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    z_mu = h @ Whz_mu + bhz_mu.repeat(h.size(0), 1)\n",
    "    z_var = h @ Whz_var + bhz_var.repeat(h.size(0), 1)\n",
    "    return z_mu, z_var\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = Variable(torch.randn(mu.shape[0], Z_dim))\n",
    "    return mu + torch.exp(log_var / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== P(X|z) ======================================\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whmu = xavier_init(size=[h_dim, X_dim])\n",
    "bhmu = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "Whsigma = xavier_init(size=[h_dim, X_dim])\n",
    "bhsigma = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "def P(z):\n",
    "    h = torch.tanh(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X_mu = (h @ Whmu + bhmu.repeat(h.size(0), 1))\n",
    "    X_sigma = (h @ Whsigma + bhsigma.repeat(h.size(0), 1))\n",
    "    return X_mu, X_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.data = torch.flatten(self.data, start_dim=1)\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(X, X)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=mb_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    print('Batch idx {}, data shape {}, target shape {}'.format(\n",
    "        batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== TRAINING ====================================\n",
    "\n",
    "params = [Wxh, bxh, Whz_mu, bhz_mu, Whz_var, bhz_var,\n",
    "          Wzh, bzh, Whmu, bhmu, Whsigma, bhsigma]\n",
    "\n",
    "solver = optim.Adam(params, lr=lr)\n",
    "\n",
    "for it in range(100):\n",
    "    for x_batch, y_batch in loader:\n",
    "        \n",
    "        # Forward\n",
    "        z_mu, z_var = Q(x_batch)\n",
    "        z = sample_z(z_mu, z_var)\n",
    "        x_sample_mu, x_sample_sigma = P(z)\n",
    "            \n",
    "\n",
    "        # Loss\n",
    "        #recon_loss = nn.binary_cross_entropy(x_sample, x_batch, size_average=False) / mb_size  # Bernoulli\n",
    "        x_sample_sigma_square = torch.diag_embed(torch.exp(x_sample_sigma), dim1=-2, dim2=-1)\n",
    "        kernels = MultivariateNormal(x_sample_mu, x_sample_sigma_square)\n",
    "#         recon_loss = kernels.log_prob(x_batch[:,None,:]).mean()\n",
    "        recon_loss = -1*kernels.log_prob(x_batch).mean()\n",
    "        kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var, 1))\n",
    "        loss = recon_loss + kl_loss\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        solver.step()\n",
    "\n",
    "        # Housekeeping\n",
    "        for p in params:\n",
    "            if p.grad is not None:\n",
    "                data = p.grad.data\n",
    "                p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if (it+1) % 10 == 0:\n",
    "        print('Iter-{}; Loss: {:.4}'.format(it+1, loss.item()))\n",
    "\n",
    "#         samples = P(z).data.numpy()[:16]\n",
    "\n",
    "#         fig = plt.figure(figsize=(4, 4))\n",
    "#         gs = gridspec.GridSpec(4, 4)\n",
    "#         gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "#         for i, sample in enumerate(samples):\n",
    "#             ax = plt.subplot(gs[i])\n",
    "#             plt.axis('off')\n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.set_aspect('equal')\n",
    "#             plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "#         if not os.path.exists('out/'):\n",
    "#             os.makedirs('out/')\n",
    "\n",
    "#         plt.savefig('out/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
    "#         c += 1\n",
    "#         plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(x_sample_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=10, centers=3, n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=10, centers=3, n_features=2, random_state=0)\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot as plt\n",
    "% notebook inline"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
